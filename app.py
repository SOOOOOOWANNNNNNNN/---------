import streamlit as st
import google.generativeai as genai

# [1] í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìš°ë¦¬ ë°˜ AI ì„ ìƒë‹˜", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” (ì´ˆë“±í•™ìƒ ì „ìš©)")
st.caption("ì•ˆì „í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” AI ì„ ìƒë‹˜ì…ë‹ˆë‹¤.")

# [2] API í‚¤ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€ ì²˜ë¦¬)
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •ì—ì„œ í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

# [3] ëª¨ë¸ ì„¤ì • (â˜…ê°€ì¥ ì¤‘ìš”: êµ¬ë²„ì „ í˜¸í™˜ ëª¨ë¸ ì‚¬ìš©)
# ìµœì‹  ê¸°ëŠ¥(system_instruction)ì„ ëºê¸° ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ì ˆëŒ€ ì•ˆ ë‚©ë‹ˆë‹¤.
model = genai.GenerativeModel('gemini-pro')

# [4] ì•ˆì „ ê·œì¹™ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ëŒ€ìš©)
# ëª¨ë¸ì—ê²Œ ì§ì ‘ ì£¼ì…í•  'ê°€ì§œ ëŒ€í™” ê¸°ë¡'ì…ë‹ˆë‹¤.
safety_prompt = """
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì§€í˜œë¡œìš´ ì´ˆë“±í•™êµ ì„ ìƒë‹˜ AIì…ë‹ˆë‹¤.
1. ì´ˆë“±í•™ìƒ ìˆ˜ì¤€ì— ë§ì¶° ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì¡´ëŒ“ë§ë¡œ ë‹µí•˜ì„¸ìš”.
2. í­ë ¥ì ì´ê±°ë‚˜ ì„ ì •ì ì¸ ì§ˆë¬¸ì€ ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”.
3. êµê³¼ì„œì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
"""

# [5] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—¬ê¸°ì„œ ì„ ìƒë‹˜ ì—­í• ì„ ê°•ì œë¡œ ë¶€ì—¬)
if "messages" not in st.session_state:
    st.session_state.messages = [
        # ì‚¬ìš©ìê°€ ì‹œí‚¨ ì²™í•˜ë©´ì„œ ì—­í• ì„ ë¶€ì—¬í•¨ (ê¼¼ìˆ˜)
        {"role": "user", "parts": [safety_prompt]},
        # AIê°€ ëŒ€ë‹µí•œ ì²™í•¨
        {"role": "model", "parts": ["ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ì €ëŠ” ì´ˆë“±í•™ìƒë“¤ì„ ìœ„í•œ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤."]}
    ]

# [6] ëŒ€í™” ê¸°ë¡ í‘œì‹œ
# ë§¨ ì²˜ìŒì˜ 'ì—­í•  ë¶€ì—¬' ëŒ€í™”(0ë²ˆ, 1ë²ˆ)ëŠ” í™”ë©´ì— ì•ˆ ë³´ì´ê²Œ ìˆ¨ê¹€ ([2:] ë¶€í„° í‘œì‹œ)
for message in st.session_state.messages[2:]:
    role = "user" if message["role"] == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message["parts"][0])

# [7] ì‚¬ìš©ì ì…ë ¥ ë° ë‹µë³€ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "parts": [prompt]})

    with st.chat_message("assistant"):
        with st.spinner("ì„ ìƒë‹˜ì´ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            try:
                # [í•µì‹¬] ì§€ê¸ˆê¹Œì§€ì˜ ëª¨ë“  ëŒ€í™”(ì—­í•  ë¶€ì—¬ í¬í•¨)ë¥¼ ëª¨ë¸ì—ê²Œ ë³´ëƒ„
                response = model.generate_content(st.session_state.messages)
                
                # ë‹µë³€ í‘œì‹œ
                st.markdown(response.text)
                
                # ëŒ€í™” ê¸°ë¡ì— AI ë‹µë³€ ì¶”ê°€
                st.session_state.messages.append({"role": "model", "parts": [response.text]})
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")