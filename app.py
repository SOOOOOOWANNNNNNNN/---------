import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()

# [1] í˜ì´ì§€ ì„¤ì •
# ëª©ì : ì›¹ ë¸Œë¼ìš°ì € íƒ­ì˜ ì œëª©ê³¼ ì•„ì´ì½˜ì„ ì„¤ì •í•˜ê³ , í™”ë©´ ìƒë‹¨ì— ì œëª©ì„ í‘œì‹œí•˜ê¸° ìœ„í•¨.
# ê²°ê³¼: ë¸Œë¼ìš°ì € íƒ­ì— 'ìš°ë¦¬ ë°˜ AI ì„ ìƒë‹˜'ì´ ë³´ì´ê³ , ë©”ì¸ í™”ë©´ì— ì œëª©ê³¼ ì„¤ëª…ì´ ë‚˜íƒ€ë‚¨.
st.set_page_config(page_title="ìš°ë¦¬ ë°˜ AI ì„ ìƒë‹˜", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” (ì´ˆë“±í•™ìƒ ì „ìš©)")
st.caption("ì•ˆì „í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” AI ì„ ìƒë‹˜ì…ë‹ˆë‹¤.")

# [2] API í‚¤ ì„¤ì • 
# [2] API í‚¤ ì„¤ì •
# ëª©ì : .env íŒŒì¼ì´ë‚˜ ìŠ¤íŠ¸ë¦¼ë¦¿ ì‹œí¬ë¦¿ì—ì„œ Google API í‚¤ë¥¼ ë¶ˆëŸ¬ì™€ AI ì„œë¹„ìŠ¤ë¥¼ ì¸ì¦í•˜ê¸° ìœ„í•¨.
# ê²°ê³¼: í‚¤ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ í‘œì‹œë˜ê³ , í‚¤ê°€ ìˆìœ¼ë©´ AI ëª¨ë¸ì„ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ì™„ë£Œë¨.
if os.getenv("GOOGLE_API_KEY"):
    api_key = os.getenv("GOOGLE_API_KEY")
    genai.configure(api_key=api_key)
elif "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# [3] ì•ˆì „ ê·œì¹™ í”„ë¡¬í”„íŠ¸ (ë‚´ìš©ì€ ë™ì¼)
safety_system_prompt = """
ë‹¹ì‹ ì€ ì•„ì´ë“¤ì„ ì‚¬ë‘í•˜ëŠ” 5ë…„ ì°¨ ë² í…Œë‘ ì´ˆë“±í•™êµ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ğŸ«
ì‚¬ìš©ìê°€ ì§€ëª…(ë‚˜ë¼, ë„ì‹œ ë“±)ì„ ì…ë ¥í•˜ë©´, ê·¸ê³³ì˜ **ìœ„ì¹˜**, **íŠ¹ì§•**, **ì¸êµ¬ìˆ˜** ë“±ì„ ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì—ì„œ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.

ì§€ì¼œì•¼ í•  ì•½ì† ğŸ¤™:
1. **ë§íˆ¬**: ì•„ì£¼ ë‹¤ì •í•˜ê³  ì¹œì ˆí•œ ì´ˆë“±í•™êµ ì„ ìƒë‹˜ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. (ì˜ˆ: "ìš°ë¦¬ ì¹œêµ¬, ê·¸ê³³ì´ ê¶ê¸ˆí–ˆêµ°ìš”!")
2. **ì´ëª¨ì§€ ì‚¬ìš©**: ëª¨ë“  ë‹µë³€ì— ì´ëª¨ì§€ë¥¼ ë“¬ë¿ ì‚¬ìš©í•´ì„œ ì•Œë¡ë‹¬ë¡í•˜ê³  ì¬ë¯¸ìˆê²Œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”! ğŸŒˆâœ¨
3. **ì„¤ëª… ë‚´ìš©**:
    - ğŸ“ **ìœ„ì¹˜**: ì–´ë””ì— ìˆëŠ”ì§€ ì‰½ê²Œ ì•Œë ¤ì£¼ì„¸ìš”.
    - ğŸŒŸ **íŠ¹ì§•**: ë¬´ì—‡ì´ ìœ ëª…í•œì§€ ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”.
    - ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ **ì¸êµ¬ìˆ˜**: ì–¼ë§ˆë‚˜ ë§ì€ ì‚¬ëŒì´ ì‚´ê³  ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
4. **ëˆˆë†’ì´ êµìœ¡**: ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” í”¼í•˜ê³ , ì‰¬ìš´ ë¹„ìœ ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
"""

# [4] ëª¨ë¸ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ system_instruction ì œê±°)
# êµ¬ë²„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œë„ 100% ì‘ë™í•˜ë„ë¡ ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
model = genai.GenerativeModel("gemini-1.5-flash")
# [4] ëª¨ë¸ ì„¤ì •
# ëª©ì : ìœ„ì—ì„œ ì •ì˜í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì ìš©í•˜ì—¬ Gemini-1.5-flash ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•¨.
# ê²°ê³¼: AIê°€ ì„ ìƒë‹˜ ì—­í• ì„ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ëœ ìƒíƒœë¡œ ëª¨ë¸ì´ ìƒì„±ë¨.
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction=system_prompt
)

# [5] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—¬ê¸°ê°€ í•µì‹¬!)
# ì‹œìŠ¤í…œ ì„¤ì •ì„ 'ì±„íŒ… ê¸°ë¡'ì˜ ë§¨ ì²˜ìŒì— ê°•ì œë¡œ ë„£ì–´ì„œ, AIê°€ ì„ ìƒë‹˜ ì—­í• ì„ í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
# [5] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ëª©ì : ì‚¬ìš©ìì™€ AIì˜ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì—¬, í™”ë©´ì´ ìƒˆë¡œê³ ì¹¨ë˜ì–´ë„ ëŒ€í™”ê°€ ìœ ì§€ë˜ë„ë¡ í•˜ê¸° ìœ„í•¨.
# ê²°ê³¼: 'messages'ë¼ëŠ” ì €ì¥ì†Œê°€ ìƒì„±ë˜ì–´ ëŒ€í™”ë¥¼ ê¸°ë¡í•  ì¤€ë¹„ê°€ ë¨.
if "messages" not in st.session_state:
    st.session_state.messages = [
        # ì‚¬ìš©ìê°€ ë§í•œ ê²ƒì²˜ëŸ¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¨¼ì € ì£¼ì…
        {"role": "user", "content": safety_system_prompt},
        # AIê°€ ì•Œê² ë‹¤ê³  ëŒ€ë‹µí•œ ê²ƒì²˜ëŸ¼ ê¸°ë¡ ì¡°ì‘
        {"role": "model", "content": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ì €ëŠ” ì´ˆë“±í•™êµ ì„ ìƒë‹˜ìœ¼ë¡œì„œ í•™ìƒë“¤ì˜ ëˆˆë†’ì´ì— ë§ì¶° ì¹œì ˆí•˜ê³  ì•ˆì „í•˜ê²Œ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤."}
    ]
    st.session_state.messages = []

# [6] ëŒ€í™” ê¸°ë¡ í‘œì‹œ
# ëª©ì : ì €ì¥ëœ ëŒ€í™” ê¸°ë¡(messages)ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ì™€ í™”ë©´ì— ì±„íŒ… ë§í’ì„ ìœ¼ë¡œ ë³´ì—¬ì£¼ê¸° ìœ„í•¨.
# ê²°ê³¼: ì‚¬ìš©ìê°€ ì´ì „ì— ë‚˜ëˆˆ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ì±„íŒ…ì°½ì— ê·¸ëŒ€ë¡œ í‘œì‹œë¨.
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# [7] ì‚¬ìš©ì ì…ë ¥ ë° ë‹µë³€ ì²˜ë¦¬
# ëª©ì : ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ í™”ë©´ì— í‘œì‹œí•˜ê³ , AIì—ê²Œ ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•œ ë’¤ í™”ë©´ì— ì¶œë ¥í•˜ê¸° ìœ„í•¨.
# ê²°ê³¼: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì±„íŒ…ì°½ì— ì§ˆë¬¸ì´ ëœ¨ê³ , ì ì‹œ í›„ AI ì„ ìƒë‹˜ì˜ ë‹µë³€ì´ ì•„ë˜ì— ë‚˜íƒ€ë‚¨.
if prompt := st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("ì„ ìƒë‹˜ì´ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            try:
                # ì €ì¥ëœ ëª¨ë“  ëŒ€í™” ê¸°ë¡(ì‹œìŠ¤í…œ ì„¤ì • í¬í•¨)ì„ AIì—ê²Œ ì „ë‹¬
                chat_history = [
                    {"role": m["role"], "parts": [m["content"]]}
                    for m in st.session_state.messages
                ]
                
                # generate_contentë¡œ ë³€ê²½ (í˜¸í™˜ì„±ì´ ê°€ì¥ ì¢‹ìŒ)
                # ëŒ€í™” ê¸°ë¡ ë³€í™˜ (Streamlit -> Gemini)
                chat_history = []
                for msg in st.session_state.messages:
                    # Streamlitì˜ 'assistant'ë¥¼ Geminiì˜ 'model'ë¡œ ë³€í™˜
                    role = "model" if msg["role"] == "assistant" else "user"
                    chat_history.append({"role": role, "parts": [msg["content"]]})

                # API ìš”ì²­
                response = model.generate_content(chat_history)
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "model", "content": response.text})
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¢€ ë” ìì„¸íˆ ì¶œë ¥
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")