import streamlit as st
import google.generativeai as genai

# [1] í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìš°ë¦¬ ë°˜ AI ì„ ìƒë‹˜", page_icon="ğŸ¤–")
st.title("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” (ì´ˆë“±í•™ìƒ ì „ìš©)")
st.caption("ì•ˆì „í•˜ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ëŠ” AI ì„ ìƒë‹˜ì…ë‹ˆë‹¤.")

# [2] API í‚¤ ì„¤ì •
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# [3] ì•ˆì „ ê·œì¹™ í”„ë¡¬í”„íŠ¸ (ë‚´ìš©ì€ ë™ì¼)
safety_system_prompt = """
ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì§€í˜œë¡œìš´ ì´ˆë“±í•™êµ ì„ ìƒë‹˜ AIì…ë‹ˆë‹¤. ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”:
1. [ë‹µë³€ ìˆ˜ì¤€]: ì´ˆë“±í•™êµ 3~6í•™ë…„ í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ì–´íœ˜ì™€ ì¹œì ˆí•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.
2. [ì•ˆì „ ê´€ë¦¬]: í­ë ¥ì , ì„ ì •ì , í˜ì˜¤ í‘œí˜„, ë²”ì£„ ëª¨ì˜ ë“± êµìœ¡ì ìœ¼ë¡œ ë¶€ì ì ˆí•œ ì§ˆë¬¸ì´ ë“¤ì–´ì˜¤ë©´ ì •ì¤‘íˆ ê±°ì ˆí•˜ì„¸ìš”.
3. [ì •ë³´ì˜ ì‹ ë¢°ì„±]: ë‹µë³€ì€ ê²€ì¦ëœ êµê³¼ì„œì  ì‚¬ì‹¤ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
4. [êµìœ¡ì  ìœ ë„]: ë‹µì„ ë°”ë¡œ ì•Œë ¤ì£¼ê¸°ë³´ë‹¤ íŒíŠ¸ë¥¼ ì£¼ì–´ ìŠ¤ìŠ¤ë¡œ ìƒê°í•˜ê²Œ í•˜ì„¸ìš”.
"""

# [4] ëª¨ë¸ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ system_instruction ì œê±°)
# êµ¬ë²„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œë„ 100% ì‘ë™í•˜ë„ë¡ ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
model = genai.GenerativeModel("gemini-1.5-flash")

# [5] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—¬ê¸°ê°€ í•µì‹¬!)
# ì‹œìŠ¤í…œ ì„¤ì •ì„ 'ì±„íŒ… ê¸°ë¡'ì˜ ë§¨ ì²˜ìŒì— ê°•ì œë¡œ ë„£ì–´ì„œ, AIê°€ ì„ ìƒë‹˜ ì—­í• ì„ í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
if "messages" not in st.session_state:
    st.session_state.messages = [
        # ì‚¬ìš©ìê°€ ë§í•œ ê²ƒì²˜ëŸ¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¨¼ì € ì£¼ì…
        {"role": "user", "content": safety_system_prompt},
        # AIê°€ ì•Œê² ë‹¤ê³  ëŒ€ë‹µí•œ ê²ƒì²˜ëŸ¼ ê¸°ë¡ ì¡°ì‘
        {"role": "model", "content": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ì €ëŠ” ì´ˆë“±í•™êµ ì„ ìƒë‹˜ìœ¼ë¡œì„œ í•™ìƒë“¤ì˜ ëˆˆë†’ì´ì— ë§ì¶° ì¹œì ˆí•˜ê³  ì•ˆì „í•˜ê²Œ ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤."}
    ]

# [6] ëŒ€í™” ê¸°ë¡ í‘œì‹œ (ì²« ë²ˆì§¸ ì‹œìŠ¤í…œ ì„¤ì • ëŒ€í™”ëŠ” í™”ë©´ì— ì•ˆ ë³´ì´ê²Œ ìˆ¨ê¹€)
# list slicing [2:]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì‹¤ì œë¡œ ì…ë ¥í•œ ëŒ€í™”ë¶€í„° ë³´ì—¬ì¤ë‹ˆë‹¤.
for message in st.session_state.messages[2:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# [7] ì‚¬ìš©ì ì…ë ¥ ë° ë‹µë³€ ì²˜ë¦¬
if prompt := st.chat_input("ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.spinner("ì„ ìƒë‹˜ì´ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
            try:
                # ì €ì¥ëœ ëª¨ë“  ëŒ€í™” ê¸°ë¡(ì‹œìŠ¤í…œ ì„¤ì • í¬í•¨)ì„ AIì—ê²Œ ì „ë‹¬
                chat_history = [
                    {"role": m["role"], "parts": [m["content"]]}
                    for m in st.session_state.messages
                ]
                
                # generate_contentë¡œ ë³€ê²½ (í˜¸í™˜ì„±ì´ ê°€ì¥ ì¢‹ìŒ)
                response = model.generate_content(chat_history)
                
                st.markdown(response.text)
                st.session_state.messages.append({"role": "model", "content": response.text})
            except Exception as e:
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¢€ ë” ìì„¸íˆ ì¶œë ¥
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")